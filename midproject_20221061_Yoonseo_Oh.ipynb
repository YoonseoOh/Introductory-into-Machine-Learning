{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoonseoOh/Introductory-into-Machine-Learning/blob/main/midproject_20221061_Yoonseo_Oh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OadkpeeQ0pCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2892c523-3870-4c5d-d6ba-f18a5bfee367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml(\"mnist_784\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = mnist.data.values, mnist.target.values\n",
        "# X = X.astype('float32')\n",
        "# y = y.astype('int')"
      ],
      "metadata": {
        "id": "rbSMgZew3l-r"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking pixel configuration for Bernoulli operations\n",
        "import numpy as np\n",
        "\n",
        "X_check = mnist.data.to_numpy()\n",
        "\n",
        "# Calculate unique pixel values\n",
        "unique_values = np.unique(X_check)\n",
        "\n",
        "# Check the range of pixel values\n",
        "min_pixel_value = np.min(unique_values)\n",
        "max_pixel_value = np.max(unique_values)\n",
        "\n",
        "print(\"Minimum Unique Pixel Value:\", min_pixel_value)\n",
        "print(\"Maximum Unique Pixel Value:\", max_pixel_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLpvCbWv3mak",
        "outputId": "2410f8ca-d9b1-4499-f602-b9caa11c9337"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Unique Pixel Value: 0.0\n",
            "Maximum Unique Pixel Value: 255.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to binary data\n",
        "X_binary = (X > 128).astype(int)"
      ],
      "metadata": {
        "id": "Ba41GW5l3nXG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Data segmentation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y, test_size=0.2, random_state=13)"
      ],
      "metadata": {
        "id": "uMAON9in3omT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Naive Bayes Model Class\n",
        "class BernoulliNBWithLog:\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        self.class_priors = np.array([np.log(np.mean(y == c)) for c in self.classes])\n",
        "\n",
        "        # Calculate the probability of each characteristic by class\n",
        "        self.feature_probs = []\n",
        "        for c in self.classes:\n",
        "            feature_prob = (X[y == c].sum(axis=0)) / (np.sum(y == c))\n",
        "            self.feature_probs.append(np.log(np.clip(feature_prob, 1e-10, 1.0 - 1e-10)))\n",
        "        self.feature_probs = np.array(self.feature_probs)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Use log-transformed characteristic probabilities and log prior probabilities to calculate log-post probabilities\n",
        "        log_likelihoods = np.dot(X, self.feature_probs.T)\n",
        "        log_posteriors = log_likelihoods + self.class_priors\n",
        "\n",
        "        # Select the class with the highest log-post probability\n",
        "        predicted_class = self.classes[np.argmax(log_posteriors, axis=1)]\n",
        "        return predicted_class"
      ],
      "metadata": {
        "id": "66lwfH9f3peq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization and training\n",
        "model = BernoulliNBWithLog()"
      ],
      "metadata": {
        "id": "kckSoPpC3qlq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "4Ld0nQzh3rpa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model with test data\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "kP-C0xh-3sfi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy calculation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "id": "_TuaH8vU3tpA",
        "outputId": "e06b3bd0-0245-4148-b83b-d96ee3d9b7ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 69.51%\n"
          ]
        }
      ]
    }
  ]
}